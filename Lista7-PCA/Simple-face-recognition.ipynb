{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "train = scipy.io.loadmat('Lista07Dane/ReducedImagesForTraining.mat')['images'].T\n",
    "test = scipy.io.loadmat('Lista07Dane/ReducedImagesForTesting.mat')['images'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLabels = (np.arange(1,251) - 1 ) // 5 + 1\n",
    "testLabels = (np.arange(1,101) - 1 ) // 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class nearestNeighbour:\n",
    "    def __init__(self, threshold, train, labels):\n",
    "        self.threshold = threshold\n",
    "        self.trainData = train\n",
    "        self.trainSquare = np.sum(train.T**2,axis=0,keepdims=True)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def predict(self, X):\n",
    "        D = -2. * np.dot(X,self.trainData.T) + self.trainSquare\n",
    "        y = self.labels[np.argmin(D, axis=1)]\n",
    "        y[np.min(D,axis=1) > self.threshold] = -1\n",
    "        return y, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nearNeigh = nearestNeighbour(np.Inf, train, trainLabels)\n",
    "predictedLabels,D = nearNeigh.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.218183e+08</td>\n",
       "      <td>-1.539194e+08</td>\n",
       "      <td>-1.112950e+08</td>\n",
       "      <td>-1.400345e+08</td>\n",
       "      <td>-1.228437e+08</td>\n",
       "      <td>-1.531005e+08</td>\n",
       "      <td>-8.370505e+07</td>\n",
       "      <td>-1.160934e+08</td>\n",
       "      <td>-7.496457e+07</td>\n",
       "      <td>-1.083911e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.898449e+07</td>\n",
       "      <td>-1.314981e+08</td>\n",
       "      <td>-1.215371e+08</td>\n",
       "      <td>-1.514494e+08</td>\n",
       "      <td>-9.266562e+07</td>\n",
       "      <td>-1.262741e+08</td>\n",
       "      <td>-1.103214e+08</td>\n",
       "      <td>-1.424997e+08</td>\n",
       "      <td>-1.203964e+08</td>\n",
       "      <td>-1.562170e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.843516e+06</td>\n",
       "      <td>1.496026e+07</td>\n",
       "      <td>7.250679e+06</td>\n",
       "      <td>1.244104e+07</td>\n",
       "      <td>9.016674e+06</td>\n",
       "      <td>1.475919e+07</td>\n",
       "      <td>5.799356e+06</td>\n",
       "      <td>7.973790e+06</td>\n",
       "      <td>6.300413e+06</td>\n",
       "      <td>7.161226e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>6.738801e+06</td>\n",
       "      <td>1.152786e+07</td>\n",
       "      <td>8.589192e+06</td>\n",
       "      <td>1.447795e+07</td>\n",
       "      <td>5.698141e+06</td>\n",
       "      <td>1.024680e+07</td>\n",
       "      <td>7.336356e+06</td>\n",
       "      <td>1.268599e+07</td>\n",
       "      <td>8.573726e+06</td>\n",
       "      <td>1.540660e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.379408e+08</td>\n",
       "      <td>-1.847107e+08</td>\n",
       "      <td>-1.229378e+08</td>\n",
       "      <td>-1.643953e+08</td>\n",
       "      <td>-1.384949e+08</td>\n",
       "      <td>-1.825873e+08</td>\n",
       "      <td>-9.226336e+07</td>\n",
       "      <td>-1.275862e+08</td>\n",
       "      <td>-8.369143e+07</td>\n",
       "      <td>-1.194984e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.103588e+08</td>\n",
       "      <td>-1.527700e+08</td>\n",
       "      <td>-1.367767e+08</td>\n",
       "      <td>-1.804006e+08</td>\n",
       "      <td>-1.030845e+08</td>\n",
       "      <td>-1.447456e+08</td>\n",
       "      <td>-1.221978e+08</td>\n",
       "      <td>-1.658495e+08</td>\n",
       "      <td>-1.355940e+08</td>\n",
       "      <td>-1.880993e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.279394e+08</td>\n",
       "      <td>-1.647857e+08</td>\n",
       "      <td>-1.164391e+08</td>\n",
       "      <td>-1.493637e+08</td>\n",
       "      <td>-1.293621e+08</td>\n",
       "      <td>-1.641585e+08</td>\n",
       "      <td>-8.788335e+07</td>\n",
       "      <td>-1.224093e+08</td>\n",
       "      <td>-7.976093e+07</td>\n",
       "      <td>-1.137047e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.040834e+08</td>\n",
       "      <td>-1.401776e+08</td>\n",
       "      <td>-1.275930e+08</td>\n",
       "      <td>-1.619578e+08</td>\n",
       "      <td>-9.704168e+07</td>\n",
       "      <td>-1.340642e+08</td>\n",
       "      <td>-1.155582e+08</td>\n",
       "      <td>-1.521069e+08</td>\n",
       "      <td>-1.262401e+08</td>\n",
       "      <td>-1.676081e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.227669e+08</td>\n",
       "      <td>-1.549125e+08</td>\n",
       "      <td>-1.117862e+08</td>\n",
       "      <td>-1.415894e+08</td>\n",
       "      <td>-1.242407e+08</td>\n",
       "      <td>-1.536878e+08</td>\n",
       "      <td>-8.534365e+07</td>\n",
       "      <td>-1.173476e+08</td>\n",
       "      <td>-7.666046e+07</td>\n",
       "      <td>-1.100685e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.905657e+07</td>\n",
       "      <td>-1.333856e+08</td>\n",
       "      <td>-1.228223e+08</td>\n",
       "      <td>-1.520216e+08</td>\n",
       "      <td>-9.262103e+07</td>\n",
       "      <td>-1.273719e+08</td>\n",
       "      <td>-1.106526e+08</td>\n",
       "      <td>-1.439908e+08</td>\n",
       "      <td>-1.214715e+08</td>\n",
       "      <td>-1.569772e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.180727e+08</td>\n",
       "      <td>-1.450243e+08</td>\n",
       "      <td>-1.084388e+08</td>\n",
       "      <td>-1.322086e+08</td>\n",
       "      <td>-1.185015e+08</td>\n",
       "      <td>-1.441233e+08</td>\n",
       "      <td>-7.981822e+07</td>\n",
       "      <td>-1.120980e+08</td>\n",
       "      <td>-7.005321e+07</td>\n",
       "      <td>-1.045031e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.488674e+07</td>\n",
       "      <td>-1.241843e+08</td>\n",
       "      <td>-1.176228e+08</td>\n",
       "      <td>-1.427850e+08</td>\n",
       "      <td>-8.852280e+07</td>\n",
       "      <td>-1.199259e+08</td>\n",
       "      <td>-1.071759e+08</td>\n",
       "      <td>-1.351344e+08</td>\n",
       "      <td>-1.165194e+08</td>\n",
       "      <td>-1.469707e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-8.909569e+07</td>\n",
       "      <td>-1.066579e+08</td>\n",
       "      <td>-8.217714e+07</td>\n",
       "      <td>-9.747705e+07</td>\n",
       "      <td>-8.942950e+07</td>\n",
       "      <td>-1.060889e+08</td>\n",
       "      <td>-6.740354e+07</td>\n",
       "      <td>-8.562108e+07</td>\n",
       "      <td>-5.764676e+07</td>\n",
       "      <td>-8.109634e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.503284e+07</td>\n",
       "      <td>-9.219488e+07</td>\n",
       "      <td>-8.874648e+07</td>\n",
       "      <td>-1.052000e+08</td>\n",
       "      <td>-7.506830e+07</td>\n",
       "      <td>-9.439742e+07</td>\n",
       "      <td>-8.125667e+07</td>\n",
       "      <td>-9.944929e+07</td>\n",
       "      <td>-8.770165e+07</td>\n",
       "      <td>-1.076082e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
       "mean  -1.218183e+08 -1.539194e+08 -1.112950e+08 -1.400345e+08 -1.228437e+08   \n",
       "std    8.843516e+06  1.496026e+07  7.250679e+06  1.244104e+07  9.016674e+06   \n",
       "min   -1.379408e+08 -1.847107e+08 -1.229378e+08 -1.643953e+08 -1.384949e+08   \n",
       "25%   -1.279394e+08 -1.647857e+08 -1.164391e+08 -1.493637e+08 -1.293621e+08   \n",
       "50%   -1.227669e+08 -1.549125e+08 -1.117862e+08 -1.415894e+08 -1.242407e+08   \n",
       "75%   -1.180727e+08 -1.450243e+08 -1.084388e+08 -1.322086e+08 -1.185015e+08   \n",
       "max   -8.909569e+07 -1.066579e+08 -8.217714e+07 -9.747705e+07 -8.942950e+07   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
       "mean  -1.531005e+08 -8.370505e+07 -1.160934e+08 -7.496457e+07 -1.083911e+08   \n",
       "std    1.475919e+07  5.799356e+06  7.973790e+06  6.300413e+06  7.161226e+06   \n",
       "min   -1.825873e+08 -9.226336e+07 -1.275862e+08 -8.369143e+07 -1.194984e+08   \n",
       "25%   -1.641585e+08 -8.788335e+07 -1.224093e+08 -7.976093e+07 -1.137047e+08   \n",
       "50%   -1.536878e+08 -8.534365e+07 -1.173476e+08 -7.666046e+07 -1.100685e+08   \n",
       "75%   -1.441233e+08 -7.981822e+07 -1.120980e+08 -7.005321e+07 -1.045031e+08   \n",
       "max   -1.060889e+08 -6.740354e+07 -8.562108e+07 -5.764676e+07 -8.109634e+07   \n",
       "\n",
       "           ...                 90            91            92            93  \\\n",
       "count      ...       2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
       "mean       ...      -9.898449e+07 -1.314981e+08 -1.215371e+08 -1.514494e+08   \n",
       "std        ...       6.738801e+06  1.152786e+07  8.589192e+06  1.447795e+07   \n",
       "min        ...      -1.103588e+08 -1.527700e+08 -1.367767e+08 -1.804006e+08   \n",
       "25%        ...      -1.040834e+08 -1.401776e+08 -1.275930e+08 -1.619578e+08   \n",
       "50%        ...      -9.905657e+07 -1.333856e+08 -1.228223e+08 -1.520216e+08   \n",
       "75%        ...      -9.488674e+07 -1.241843e+08 -1.176228e+08 -1.427850e+08   \n",
       "max        ...      -7.503284e+07 -9.219488e+07 -8.874648e+07 -1.052000e+08   \n",
       "\n",
       "                 94            95            96            97            98  \\\n",
       "count  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02  2.500000e+02   \n",
       "mean  -9.266562e+07 -1.262741e+08 -1.103214e+08 -1.424997e+08 -1.203964e+08   \n",
       "std    5.698141e+06  1.024680e+07  7.336356e+06  1.268599e+07  8.573726e+06   \n",
       "min   -1.030845e+08 -1.447456e+08 -1.221978e+08 -1.658495e+08 -1.355940e+08   \n",
       "25%   -9.704168e+07 -1.340642e+08 -1.155582e+08 -1.521069e+08 -1.262401e+08   \n",
       "50%   -9.262103e+07 -1.273719e+08 -1.106526e+08 -1.439908e+08 -1.214715e+08   \n",
       "75%   -8.852280e+07 -1.199259e+08 -1.071759e+08 -1.351344e+08 -1.165194e+08   \n",
       "max   -7.506830e+07 -9.439742e+07 -8.125667e+07 -9.944929e+07 -8.770165e+07   \n",
       "\n",
       "                 99  \n",
       "count  2.500000e+02  \n",
       "mean  -1.562170e+08  \n",
       "std    1.540660e+07  \n",
       "min   -1.880993e+08  \n",
       "25%   -1.676081e+08  \n",
       "50%   -1.569772e+08  \n",
       "75%   -1.469707e+08  \n",
       "max   -1.076082e+08  \n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(D.T).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((predictedLabels != testLabels).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PCA(X):\n",
    "    X_std = (X - np.mean(X,axis=0)) / np.std(X,axis=0)\n",
    "    S = np.cov(X_std.T)\n",
    "    Λ,V = np.linalg.eigh(S)\n",
    "    Y = X_std.dot(V) / np.sqrt(np.abs(Λ))\n",
    "    return Y, Λ, V\n",
    "\n",
    "def reduceDimensionality(X, Λ, V, k):\n",
    "    Y = (X * np.sqrt(np.abs(Λ)))[:,-k:].dot(V.T[-k:,:])\n",
    "    return Y\n",
    "\n",
    "def restoreData(Y, Λ, V, X, k):\n",
    "    Z_std = reduceDimensionality(Y, Λ, V, k)\n",
    "    Z = Z_std * X.std(axis=0) + X.mean(axis=0)\n",
    "    return Z\n",
    "\n",
    "def reduceTestData(X,k,Λ,V):\n",
    "    X_std = (X - np.mean(X,axis=0)) / np.std(X,axis=0)\n",
    "    Y = X_std.dot(V) / np.sqrt(np.abs(Λ))\n",
    "    Z = reduceDimensionality(Y,Λ,V,k)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y, Λ, V = PCA(train)\n",
    "Z = reduceDimensionality(Y,Λ,V,100)\n",
    "reducedTest = reduceTestData(test, 100, Λ, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nearNeighPCA = nearestNeighbour(np.Inf, Z, trainLabels)\n",
    "predictedLabelsPCA,D = nearNeighPCA.predict(reducedTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((predictedLabelsPCA != testLabels).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(5)\n",
    "knn.fit(train,trainLabels)\n",
    "predictedknnLbls = knn.predict(test)\n",
    "np.sum((predictedknnLbls != testLabels).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnPCA = KNeighborsClassifier(5)\n",
    "knnPCA.fit(Z,trainLabels)\n",
    "predictedknnPCALbls = knnPCA.predict(reducedTest)\n",
    "np.sum((predictedknnPCALbls != testLabels).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knnComparision():\n",
    "    errList = []\n",
    "    for k in range(1,16,2):\n",
    "        for dim in range(100,1000,100):\n",
    "            Y, Λ, V = PCA(train)\n",
    "            Z = reduceDimensionality(Y,Λ,V,dim)\n",
    "            reducedTest = reduceTestData(test, dim, Λ, V)\n",
    "            knnPCA = KNeighborsClassifier(k)\n",
    "            knnPCA.fit(Z,trainLabels)\n",
    "            predictedknnPCALbls = knnPCA.predict(reducedTest)\n",
    "            errList.append(np.sum((predictedknnPCALbls != testLabels).astype(np.int)))\n",
    "    return errList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errs = knnComparision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 8, 7, 7, 7, 7, 7, 7, 7, 22, 20, 21, 21, 21, 21, 21, 21, 21, 23, 20, 21, 21, 21, 21, 21, 21, 21, 23, 20, 19, 19, 19, 19, 19, 19, 19, 24, 22, 24, 24, 24, 24, 24, 24, 24, 27, 30, 29, 29, 29, 29, 29, 29, 29, 29, 28, 29, 29, 29, 29, 29, 29, 29, 34, 35, 36, 36, 36, 36, 36, 36, 36]\n"
     ]
    }
   ],
   "source": [
    "print(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 4921)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWithLabels = np.append(train, trainLabels[:,np.newaxis], axis=1)\n",
    "testWithLabels = np.append(test, testLabels[:,np.newaxis], axis=1)\n",
    "allData = np.append(trainWithLabels, testWithLabels, axis=0)\n",
    "allData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationComparision(data, krange, dimrange, validtime):\n",
    "    errList = []\n",
    "    for k in krange:\n",
    "        for dim in dimrange:\n",
    "            err = 0\n",
    "            for i in range(validtime):\n",
    "                np.random.shuffle(data)\n",
    "                trainData = data[:300,:-1]\n",
    "                trainLabels = data[:300,-1]\n",
    "                testData = data[300:,:-1]\n",
    "                testLabels = data[300:,-1]\n",
    "                Y, Λ, V = PCA(trainData)\n",
    "                Z = reduceDimensionality(Y,Λ,V,dim)\n",
    "                reducedTest = reduceTestData(testData, dim, Λ, V)\n",
    "                knnPCA = KNeighborsClassifier(k)\n",
    "                knnPCA.fit(Z,trainLabels)\n",
    "                predictedknnPCALbls = knnPCA.predict(reducedTest)\n",
    "                err += np.sum((predictedknnPCALbls != testLabels).astype(np.int))\n",
    "            err /= validtime    \n",
    "            errList.append((k,dim,err))\n",
    "            print('Average error for k = ',k,' and dim = ',dim,'  : ',err)\n",
    "    return errList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error for k =  1  and dim =  10   :  32.6\n",
      "Average error for k =  1  and dim =  100   :  25.6\n",
      "Average error for k =  1  and dim =  300   :  27.2\n",
      "Average error for k =  1  and dim =  500   :  26.8\n",
      "Average error for k =  1  and dim =  1000   :  24.2\n",
      "Average error for k =  3  and dim =  10   :  32.4\n",
      "Average error for k =  3  and dim =  100   :  30.2\n",
      "Average error for k =  3  and dim =  300   :  26.6\n",
      "Average error for k =  3  and dim =  500   :  29.4\n",
      "Average error for k =  3  and dim =  1000   :  32.4\n",
      "Average error for k =  5  and dim =  10   :  36.6\n",
      "Average error for k =  5  and dim =  100   :  32.8\n",
      "Average error for k =  5  and dim =  300   :  34.0\n",
      "Average error for k =  5  and dim =  500   :  32.8\n",
      "Average error for k =  5  and dim =  1000   :  32.0\n"
     ]
    }
   ],
   "source": [
    "errList = crossValidationComparision(allData,[1,3,5], [10,100,300,500,1000], 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
